{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "* First, replicating the analysis done in http://blog.yhat.com/posts/harry-potter-classification.html\n",
    "* Second, pulling in additional data trying Naive Bayes instead to do multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in data from Harry Potter wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:45:19.386210Z",
     "start_time": "2017-07-16T21:45:19.381566-04:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hide_input": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:45:20.544959Z",
     "start_time": "2017-07-16T21:45:20.541582-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "houses = ['Gryffindor', 'Ravenclaw', 'Hufflepuff', 'Slytherin']\n",
    "base_url = \"http://harrypotter.wikia.com/api/v1/Articles/List?expand=1&limit=1000&category=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:45:28.215655Z",
     "start_time": "2017-07-16T21:45:21.944252-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull in articles about characters in each house\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for house in houses:\n",
    "    formatted_url = base_url + house + 's'\n",
    "    r = requests.get(formatted_url)\n",
    "    info = r.json()\n",
    "    # pull the data we want into a dataframe with the house name\n",
    "    temp = pd.DataFrame(info['items'])[['id', 'title', 'url', 'type']]\n",
    "    temp = temp[temp.type == 'article']\n",
    "    temp.drop(['type'], axis=1, inplace=True)\n",
    "    temp['house'] = pd.Series([house] * len(temp))\n",
    "    # add it into the final dataset\n",
    "    data = pd.concat([data, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:45:30.436402Z",
     "start_time": "2017-07-16T21:45:30.419868-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33349</td>\n",
       "      <td>Astrix Alixan</td>\n",
       "      <td>/wiki/Astrix_Alixan</td>\n",
       "      <td>Gryffindor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33353</td>\n",
       "      <td>Filemina Alchin</td>\n",
       "      <td>/wiki/Filemina_Alchin</td>\n",
       "      <td>Gryffindor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7018</td>\n",
       "      <td>Euan Abercrombie</td>\n",
       "      <td>/wiki/Euan_Abercrombie</td>\n",
       "      <td>Gryffindor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99282</td>\n",
       "      <td>Sakura Akagi</td>\n",
       "      <td>/wiki/Sakura_Akagi</td>\n",
       "      <td>Gryffindor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99036</td>\n",
       "      <td>Zakir Akram</td>\n",
       "      <td>/wiki/Zakir_Akram</td>\n",
       "      <td>Gryffindor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             title                     url       house\n",
       "1  33349     Astrix Alixan     /wiki/Astrix_Alixan  Gryffindor\n",
       "2  33353   Filemina Alchin   /wiki/Filemina_Alchin  Gryffindor\n",
       "3   7018  Euan Abercrombie  /wiki/Euan_Abercrombie  Gryffindor\n",
       "4  99282      Sakura Akagi      /wiki/Sakura_Akagi  Gryffindor\n",
       "5  99036       Zakir Akram       /wiki/Zakir_Akram  Gryffindor"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:45:32.622142Z",
     "start_time": "2017-07-16T21:45:32.607153-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gryffindor</th>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hufflepuff</th>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ravenclaw</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slytherin</th>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  title  url\n",
       "house                      \n",
       "Gryffindor  238    238  238\n",
       "Hufflepuff  147    147  147\n",
       "Ravenclaw   151    151  151\n",
       "Slytherin   206    206  206"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like we have between 150-240 characters in each house\n",
    "# makes sense there would be more in Gryffindor & Slytherin because Hufflepuffs are boring af\n",
    "data.groupby('house').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:45:34.666810Z",
     "start_time": "2017-07-16T21:45:34.659718-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749\n",
      "749\n"
     ]
    }
   ],
   "source": [
    "# no dupes / no characters found to be in multiple houses / no double crossers!\n",
    "print len(data.id)\n",
    "print len(data.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:48:40.998411Z",
     "start_time": "2017-07-16T21:48:27.572826-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "article_id_text = {}\n",
    "base_url = \"http://harrypotter.wikia.com/api/v1/Articles/AsSimpleJson?id=\"\n",
    "\n",
    "# loops through articles for characters in each house\n",
    "for article_id in data.id:\n",
    "    formatted_url = base_url + str(article_id)\n",
    "    r = requests.get(formatted_url)\n",
    "    sections = r.json()['sections']\n",
    "    # pull in the content section if there is a Personality and Traits sections\n",
    "    content = [sections[i]['content'] for i, x in enumerate(sections) if sections[i]['title'] == 'Personality and traits']\n",
    "    if content:\n",
    "        paragraphs = content[0]\n",
    "        text = [paragraphs[i]['text'] for i, x in enumerate(paragraphs)]\n",
    "        all_text = ' '.join(text)\n",
    "    else:\n",
    "        all_text = ''\n",
    "    \n",
    "    article_id_text[article_id] = all_text\n",
    "\n",
    "text_data = pd.DataFrame.from_dict(article_id_text, orient='index').reset_index()\n",
    "text_data.columns = ['id', 'text']\n",
    "text_data['text_length'] = text_data.text.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:48:44.309340Z",
     "start_time": "2017-07-16T21:48:44.296181-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine article data with character data\n",
    "# and then filter out characters with no article data\n",
    "df = pd.merge(data, text_data, on='id', how='left')\n",
    "df = df[df.text_length > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:48:45.524887Z",
     "start_time": "2017-07-16T21:48:45.513494-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house\n",
       "Gryffindor    42\n",
       "Hufflepuff    11\n",
       "Ravenclaw     15\n",
       "Slytherin     26\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# welp, this dramatically reduces the size of our dataset\n",
    "df.groupby('house').count()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use NLTK to pull in a list of traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T00:50:33.191955Z",
     "start_time": "2017-07-15T20:50:33.187552-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import copy\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:48:58.445873Z",
     "start_time": "2017-07-16T21:48:58.436532-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from these manually curated baseline list of traits\n",
    "# build upon it to pull in all synonyms and antonyms for traits and anti-traits\n",
    "trait_dict = {}\n",
    "trait_dict['Gryffindor'] = [\n",
    "    'bravery',\n",
    "    'nerve',\n",
    "    'chivalry',\n",
    "    'daring',\n",
    "    'courage',\n",
    "]\n",
    "trait_dict['Slytherin'] = [\n",
    "    'resourceful',\n",
    "    'cunning',\n",
    "    'ambition',\n",
    "    'determination',\n",
    "    'self-preservation',\n",
    "    'fraternity',\n",
    "    'cleverness',\n",
    "]\n",
    "trait_dict['Ravenclaw'] = [\n",
    "    'intelligence',\n",
    "    'wit',\n",
    "    'wisdom',\n",
    "    'creativity',\n",
    "    'originality',\n",
    "    'individuality',\n",
    "    'acceptance',\n",
    "]\n",
    "trait_dict['Hufflepuff'] = [\n",
    "    'dedication',\n",
    "    'diligence',\n",
    "    'fairness',\n",
    "    'patience',\n",
    "    'kindness',\n",
    "    'tolerance',\n",
    "    'persistence',\n",
    "    'loyalty',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T00:37:44.535670Z",
     "start_time": "2017-07-15T20:37:44.520025-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# again, manually curated synonyms\n",
    "relevant_synsets = {}\n",
    "relevant_synsets['Ravenclaw'] = [\n",
    "    wn.synset('intelligence.n.01'), wn.synset('wit.n.01'), wn.synset('brain.n.02'),\n",
    "    wn.synset('wisdom.n.01'), wn.synset('wisdom.n.02'), wn.synset('wisdom.n.03'),\n",
    "    wn.synset('wisdom.n.04'), wn.synset('creativity.n.01'), wn.synset('originality.n.01'),\n",
    "    wn.synset('originality.n.02'), wn.synset('individuality.n.01'), wn.synset('credence.n.01'),\n",
    "    wn.synset('acceptance.n.03')\n",
    "]\n",
    "relevant_synsets['Hufflepuff'] = [\n",
    "    wn.synset('dedication.n.01'), wn.synset('commitment.n.04'), wn.synset('commitment.n.02'),\n",
    "    wn.synset('diligence.n.01'), wn.synset('diligence.n.02'), wn.synset('application.n.06'),\n",
    "    wn.synset('fairness.n.01'), wn.synset('fairness.n.01'), wn.synset('patience.n.01'),\n",
    "    wn.synset('kindness.n.01'), wn.synset('forgivingness.n.01'), wn.synset('kindness.n.03'),\n",
    "    wn.synset('tolerance.n.03'), wn.synset('tolerance.n.04'), wn.synset('doggedness.n.01'),\n",
    "    wn.synset('loyalty.n.01'), wn.synset('loyalty.n.02')\n",
    "]\n",
    "relevant_synsets['Gryffindor'] = [\n",
    "    wn.synset('courage.n.01'), wn.synset('fearlessness.n.01'), wn.synset('heart.n.03'),\n",
    "    wn.synset('boldness.n.02'), wn.synset('chivalry.n.01'), wn.synset('boldness.n.01')\n",
    "]\n",
    "relevant_synsets['Slytherin'] = [\n",
    "    wn.synset('resourcefulness.n.01'), wn.synset('resource.n.03'), wn.synset('craft.n.05'),\n",
    "    wn.synset('cunning.n.02'), wn.synset('ambition.n.01'), wn.synset('ambition.n.02'),\n",
    "    wn.synset('determination.n.02'), wn.synset('determination.n.04'),\n",
    "    wn.synset('self-preservation.n.01'), wn.synset('brotherhood.n.02'),\n",
    "    wn.synset('inventiveness.n.01'), wn.synset('brightness.n.02'), wn.synset('ingenuity.n.02')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T00:37:46.381929Z",
     "start_time": "2017-07-15T20:37:46.342550-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_forms(lemma):\n",
    "    drfs = lemma.derivationally_related_forms()\n",
    "    output_list = []\n",
    "    if drfs:\n",
    "        for drf in drfs:\n",
    "            drf_pos = str(drf).split(\".\")[1]\n",
    "            if drf_pos in ['n', 's', 'a']:\n",
    "                output_list.append(drf.name().lower())\n",
    "                if drf_pos in ['s', 'a']:\n",
    "                    if len(drf.name()) == 3:\n",
    "                        last_letter = drf.name()[-1:]\n",
    "                        output_list.append(drf.name().lower() + last_letter + 'er')\n",
    "                        output_list.append(drf.name().lower() + last_letter + 'est')\n",
    "                        output_list.append(drf.name().lower()+'ness')\n",
    "                        output_list.append(drf.name().lower()+'ly')\n",
    "                    elif drf.name()[-4:] in ['able', 'ible']:\n",
    "                        output_list.append(drf.name().lower()+'r')\n",
    "                        output_list.append(drf.name().lower()+'st')\n",
    "                        output_list.append(drf.name().lower()+'ness')\n",
    "                        output_list.append(drf.name()[:-1].lower()+'y')\n",
    "                    elif drf.name()[-1:] == 'e':\n",
    "                        output_list.append(drf.name().lower()+'r')\n",
    "                        output_list.append(drf.name().lower()+'st')\n",
    "                        output_list.append(drf.name().lower()+'ness')\n",
    "                        output_list.append(drf.name().lower()+'ly')\n",
    "                    elif drf.name()[-2:] == 'ic':\n",
    "                        output_list.append(drf.name().lower()+'er')\n",
    "                        output_list.append(drf.name().lower()+'est')\n",
    "                        output_list.append(drf.name().lower()+'ness')\n",
    "                        output_list.append(drf.name().lower()+'ally')\n",
    "                    elif drf.name()[-1:] == 'y':\n",
    "                        output_list.append(drf.name()[:-1].lower()+'ier')\n",
    "                        output_list.append(drf.name()[:-1].lower()+'iest')\n",
    "                        output_list.append(drf.name()[:-1].lower()+'iness')\n",
    "                        output_list.append(drf.name()[:-1].lower()+'ily')\n",
    "                    else:\n",
    "                        output_list.append(drf.name().lower()+'er')\n",
    "                        output_list.append(drf.name().lower()+'est')\n",
    "                        output_list.append(drf.name().lower()+'ness')\n",
    "                        output_list.append(drf.name().lower()+'ly')\n",
    "        return output_list\n",
    "    else:\n",
    "        return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:49:04.074939Z",
     "start_time": "2017-07-16T21:49:04.070890-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_trait_dict = copy.deepcopy(trait_dict)\n",
    "antonym_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:49:04.734164Z",
     "start_time": "2017-07-16T21:49:04.709180-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add synonyms and word forms to the (new) trait dictionary\n",
    "# Also add antonyms (and their word forms) to the antonym dictionary\n",
    "for house, traits in trait_dict.items():\n",
    "    antonym_dict[house] = []\n",
    "    for trait in traits:\n",
    "        # first get a list of the synsets for each trait that we've curated above\n",
    "        synsets = wn.synsets(trait, pos=wn.NOUN)\n",
    "        for synset in synsets:\n",
    "            # if the synset is within the relevant synsets that we've also curated above then go ahead\n",
    "            if synset in relevant_synsets[house]:\n",
    "                for lemma in synset.lemmas():\n",
    "                    # put the synonym into the dictionary\n",
    "                    new_trait_dict[house].append(lemma.name().lower())\n",
    "                    # and if there are additional forms of it, add it into the list as well\n",
    "                    if get_forms(lemma):\n",
    "                        new_trait_dict[house].extend(get_forms(lemma))\n",
    "                    # and if there are any antonyms, put it into the antonyms dictionary\n",
    "                    if lemma.antonyms():\n",
    "                        for antonym in lemma.antonyms():\n",
    "                            antonym_dict[house].append(antonym.name().lower())\n",
    "                            if get_forms(antonym):\n",
    "                                antonym_dict[house].extend(get_forms(antonym))\n",
    "    # then let's make sure that all the words are unique and sorted for each house\n",
    "    new_trait_dict[house] = sorted(list(set(new_trait_dict[house])))\n",
    "    antonym_dict[house] = sorted(list(set(antonym_dict[house])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:49:07.127675Z",
     "start_time": "2017-07-16T21:49:07.120308-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure that there aren't repeat words across houses in each of the traits and antonyms dict\n",
    "def is_no_overlap(dict):\n",
    "    results = []\n",
    "    # create pairs of houses using itertools combinations\n",
    "    house_pairs = list(combinations(dict.keys(), 2))\n",
    "    for pair in house_pairs:\n",
    "        # check if two sets are separate\n",
    "        results.append(set(dict[pair[0]]).isdisjoint(dict[pair[1]]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:49:07.613822Z",
     "start_time": "2017-07-16T21:49:07.606191-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True]\n",
      "[True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print is_no_overlap(new_trait_dict)\n",
    "print is_no_overlap(antonym_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Students into Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T01:20:16.458637Z",
     "start_time": "2017-07-15T21:20:16.455352-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T23:52:57.275133Z",
     "start_time": "2017-07-16T19:52:57.266325-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input text\n",
    "# output house\n",
    "def sorting_hat(text):\n",
    "    scores = defaultdict(int)\n",
    "    word_list = [word.lower() for word in word_tokenize(text)]\n",
    "    for house in houses:\n",
    "        scores[house] = sum([True for word in word_list if word in new_trait_dict[house]]) - sum([True for word in word_list if word in antonym_dict[house]])\n",
    "    sorted_house = max(scores, key=scores.get)\n",
    "    if sum([True for i in scores.values() if i==scores[sorted_house]]) == 1:\n",
    "        return sorted_house\n",
    "    else:\n",
    "        return 'Tie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:49:13.982681Z",
     "start_time": "2017-07-16T21:49:13.070462-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['sorted_house'] = df['text'].map(lambda x: sorting_hat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:49:14.020131Z",
     "start_time": "2017-07-16T21:49:13.984509-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>house</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sorted_house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>325</td>\n",
       "      <td>Katie Bell</td>\n",
       "      <td>/wiki/Katie_Bell</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Katie was a friendly person who was very inter...</td>\n",
       "      <td>698</td>\n",
       "      <td>Tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31</td>\n",
       "      <td>Sirius Black</td>\n",
       "      <td>/wiki/Sirius_Black</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Sirius was true to the ideal of a Gryffindor s...</td>\n",
       "      <td>3483</td>\n",
       "      <td>Hufflepuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20</td>\n",
       "      <td>Lavender Brown</td>\n",
       "      <td>/wiki/Lavender_Brown</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Lavender was a somewhat silly and sentimental ...</td>\n",
       "      <td>585</td>\n",
       "      <td>Gryffindor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>449</td>\n",
       "      <td>Colin Creevey</td>\n",
       "      <td>/wiki/Colin_Creevey</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Colin was a person who was very easily excited...</td>\n",
       "      <td>1457</td>\n",
       "      <td>Slytherin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>451</td>\n",
       "      <td>Dennis Creevey</td>\n",
       "      <td>/wiki/Dennis_Creevey</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Dennis apparently had a similar personality to...</td>\n",
       "      <td>185</td>\n",
       "      <td>Slytherin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           title                   url       house  \\\n",
       "16  325      Katie Bell      /wiki/Katie_Bell  Gryffindor   \n",
       "23   31    Sirius Black    /wiki/Sirius_Black  Gryffindor   \n",
       "30   20  Lavender Brown  /wiki/Lavender_Brown  Gryffindor   \n",
       "45  449   Colin Creevey   /wiki/Colin_Creevey  Gryffindor   \n",
       "46  451  Dennis Creevey  /wiki/Dennis_Creevey  Gryffindor   \n",
       "\n",
       "                                                 text  text_length  \\\n",
       "16  Katie was a friendly person who was very inter...          698   \n",
       "23  Sirius was true to the ideal of a Gryffindor s...         3483   \n",
       "30  Lavender was a somewhat silly and sentimental ...          585   \n",
       "45  Colin was a person who was very easily excited...         1457   \n",
       "46  Dennis apparently had a similar personality to...          185   \n",
       "\n",
       "   sorted_house  \n",
       "16          Tie  \n",
       "23   Hufflepuff  \n",
       "30   Gryffindor  \n",
       "45    Slytherin  \n",
       "46    Slytherin  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:49:18.810445Z",
     "start_time": "2017-07-16T21:49:18.800848-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sorted_house\n",
       "Gryffindor    16\n",
       "Hufflepuff    18\n",
       "Ravenclaw     18\n",
       "Slytherin     11\n",
       "Tie           32\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sorted_house').count()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:49:20.620796Z",
     "start_time": "2017-07-16T21:49:20.612779-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of ties: 33.68\n",
      "% of matches: 26.32\n"
     ]
    }
   ],
   "source": [
    "# pct of ties\n",
    "print \"% of ties: \" + \"{0:.2f}\".format(len(df[df.sorted_house=='Tie'])/float(len(df))*100)\n",
    "# pct of matches - damn, this is sucks\n",
    "print \"% of matches: \" + \"{0:.2f}\".format(len(df[df.sorted_house==df.house])/float(len(df))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>naive bayes</b> methods are supervised learning algorithms that applies bayes theorem\n",
    "  * naive assumption of independence between every pair of features\n",
    "  * not the best for actual prediction probabilities but good for classification\n",
    "* <b>gaussiannb</b> assumes a gaussian distribution for the likelihood of a given feature for a given class\n",
    "* <b>multinomialnb</b> assumes multinomially distributed data\n",
    "  * most suitable for text classification, data is represented as word vector counts (tf-idf also works)\n",
    "  * smoothing prevents zero probabilities in computation e.g. laplace smoothing (prob of x = (count of x + k) / N + k * count of x)\n",
    "* <b>bernoullinb</b> assumes features are bernoulli - different from multinomial and explicitly penalizes the non-occurrence of a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T01:51:32.801312Z",
     "start_time": "2017-07-16T21:51:32.796733-04:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* converting data into <b>bag of words</b> representation where each column is a unique word and each row is a character (typically, high dimensional sparse datasets)\n",
    "* can use countvectorizer in sklearn to tokenize the text data (can also support n-grams)\n",
    "* occurrence count can be problematic though because larger documents will have higher counts; in that case, use <b>term frequencies (tf)</b> which is the occurrence divided by the total occurrences\n",
    "* then you might want to de-emphasize words that are common to all documents, which brings us to <b>term frequency times inverse document frequency (tf-idf)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df.house.isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T12:19:12.325623Z",
     "start_time": "2017-07-17T08:19:12.038466-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 37754)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are vectorizing all of the unique words in each character description\n",
    "# we have 95 characters and 5096 unique words\n",
    "count_vect = CountVectorizer(ngram_range=(1,3), stop_words='english')\n",
    "X_counts = count_vect.fit_transform(df['text'].values)\n",
    "X_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T12:19:13.348274Z",
     "start_time": "2017-07-17T08:19:13.337009-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 37754)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out term frequency and inverse term frequencies\n",
    "X_tfidf = TfidfTransformer(use_idf=True,).fit_transform(X_counts)\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T12:19:14.090828Z",
     "start_time": "2017-07-17T08:19:14.083057-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94,)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is the house they belong to\n",
    "df['house_target'] = df['house'].map(lambda x: houses.index(x))\n",
    "y = df['house_target'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T12:19:14.821717Z",
     "start_time": "2017-07-17T08:19:14.775649-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42857142857142855,\n",
       " 0.47368421052631576,\n",
       " 0.44444444444444442,\n",
       " 0.44444444444444442,\n",
       " 0.44444444444444442]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# welp, less than 50% match with naive bayes multinomial on tf idf of text\n",
    "accuracy = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=213, shuffle=True)\n",
    "for train, test in skf.split(X_tfidf, y):\n",
    "    predicted_house = MultinomialNB().fit(X_tfidf[train], y[train]).predict(X_tfidf[test])\n",
    "    accuracy.append(sum(y[test]==predicted_house)/float(len(y[test])))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T12:19:15.950826Z",
     "start_time": "2017-07-17T08:19:15.890982-04:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47619047619047616,\n",
       " 0.42105263157894735,\n",
       " 0.3888888888888889,\n",
       " 0.44444444444444442,\n",
       " 0.44444444444444442]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# welp, less than 50% match with naive bayes bernoulli on tf idf of text\n",
    "# not super successful - should try to see if more/better data is need, more refinement of features\n",
    "accuracy = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=213, shuffle=True)\n",
    "for train, test in skf.split(X_tfidf, y):\n",
    "    predicted_house = BernoulliNB().fit(X_tfidf[train], y[train]).predict(X_tfidf[test])\n",
    "    accuracy.append(sum(y[test]==predicted_house)/float(len(y[test])))\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "13px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
